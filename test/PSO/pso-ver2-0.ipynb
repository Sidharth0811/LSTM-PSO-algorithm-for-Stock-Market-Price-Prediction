{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yfinance","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:15:28.353305Z","iopub.execute_input":"2024-04-09T11:15:28.354261Z","iopub.status.idle":"2024-04-09T11:16:02.716231Z","shell.execute_reply.started":"2024-04-09T11:15:28.354215Z","shell.execute_reply":"2024-04-09T11:16:02.715113Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting yfinance\n  Downloading yfinance-0.2.37-py2.py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.1.4)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.31.0)\nCollecting multitasking>=0.0.7 (from yfinance)\n  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (5.2.1)\nRequirement already satisfied: appdirs>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.4.4)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2023.3.post1)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.4.1)\nCollecting peewee>=3.16.2 (from yfinance)\n  Downloading peewee-3.17.1.tar.gz (3.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.2)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.2.2)\nDownloading yfinance-0.2.37-py2.py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\nBuilding wheels for collected packages: peewee\n  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.1-cp310-cp310-linux_x86_64.whl size=291653 sha256=d903b9f002932172a19bcade47fe149ed133409a491e7281af75e464daafbb53\n  Stored in directory: /root/.cache/pip/wheels/d7/35/5c/1374782be033462df5f40174d8d879519d64ed8c25a1977554\nSuccessfully built peewee\nInstalling collected packages: peewee, multitasking, yfinance\nSuccessfully installed multitasking-0.0.11 peewee-3.17.1 yfinance-0.2.37\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a directory if it is not there, so we can save files and results in it\nfrom pathlib import Path\nPath('/kaggle/working/PSO').mkdir(parents=True,exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:16:02.718286Z","iopub.execute_input":"2024-04-09T11:16:02.718581Z","iopub.status.idle":"2024-04-09T11:16:02.723663Z","shell.execute_reply.started":"2024-04-09T11:16:02.718554Z","shell.execute_reply":"2024-04-09T11:16:02.722730Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"notebooka94414a4a1\n\nAutomatically generated by Colaboratory.\n\nOriginal file is located at\n    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/notebooka94414a4a1-780af299-0af7-47f5-8d22-fbda06b2cfac.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240409/auto/storage/goog4_request%26X-Goog-Date%3D20240409T060240Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2a380db4b5c7c975d672260e4a1cfddac2ca862101743509ae673b4ce1adf614a57c12f2035a06d4c45d0dd4c364e44d77dffb9ed4366cc9e9eec3f9c4e3168cf60be9d9e2b9c8aae18437720530b663922c05aaf84f422131cd95346b33b45448998deedc542a2de88805b3d53237d6bddaf32b9d7dc27a07613a58f86577111558ac04060ff48e761fc184e6f7db48697c83031fb9ced6fbc4146acc6236fd740df8eba740c27f77c04a92385a642eeb3a3f00c0a44e398be6f81448a60edb1f70c3d138aab39759b06fa26e8fbc755ef6ac06202b26c4bf4a345d7c16b1346f644b62267e987ce8ae94d7cd377d19eea834ca86c9abe523c6284541454ebe\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport yfinance as yf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n\ndef stock_predict(stockname,filename):\n\n    # Download stock data\n    symbol = stockname\n    start_date = '2019-01-01'\n    end_date = '2024-01-01'\n    stock_data = yf.download(symbol, start=start_date, end=end_date)\n    specific_df = pd.DataFrame(stock_data).reset_index()\n\n    # Preprocess stock data\n    specific_df['Date'] = pd.to_datetime(specific_df['Date'])\n    specific_df['Year'] = specific_df['Date'].dt.year\n    specific_df['Month'] = specific_df['Date'].dt.month\n    specific_df['Day'] = specific_df['Date'].dt.day\n\n    # Normalize data\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(specific_df[['Close']])\n\n    # Split data into training and testing sets\n    train_size = int(len(scaled_data) * 0.8)\n    train_data, test_data = scaled_data[0:train_size, :], scaled_data[train_size:len(scaled_data), :]\n\n    # Generate sequences and labels for LSTM\n    def generate_sequences_and_labels(data, n_past):\n        sequences, labels = [], []\n        for i in range(len(data) - n_past):\n            sequences.append(data[i:i + n_past])\n            labels.append(data[i + n_past, 0])\n        return np.array(sequences), np.array(labels)\n\n    n_past = 2\n    x_train, y_train = generate_sequences_and_labels(train_data, n_past)\n    x_test, y_test = generate_sequences_and_labels(test_data, n_past)\n    x_train_lstm = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n    x_test_lstm = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n    \n    ################################ START ###########################################\n\n    def objective_function(params, X_train, Y_train, X_test, Y_test):\n        lstm_units, dropout_rate, dense_units = params\n\n        model = Sequential()\n        model.add(LSTM(units=int(lstm_units), return_sequences=True, input_shape=(n_past, 1)))\n        model.add(Dropout(dropout_rate))\n        model.add(LSTM(units=int(lstm_units/2), return_sequences=False))\n        model.add(Dropout(dropout_rate))\n        model.add(Dense(int(dense_units), activation='relu'))\n        model.add(Dense(1))\n\n        model.compile(optimizer='adam', loss='mean_squared_error')\n        model.fit(X_train, Y_train, epochs=100, verbose=0)\n\n        predictions = model.predict(X_test)\n        r2 = r2_score(Y_test, predictions)\n        #mse = mean_squared_error(Y_test, predictions)\n        return -r2  # negative R-squared for minimization\n\n    def particle_swarm_optimization(objective_function, no_particle, no_dim, x_range, v_range, iw_range, c, X_train, Y_train, X_test, Y_test, print_step, iter):\n\n        particles = np.random.uniform([r[0] for r in x_range], [r[1] for r in x_range], size=(no_particle, no_dim))\n        velocities = np.random.uniform([r[0] for r in v_range], [r[1] for r in v_range], size=(no_particle, no_dim))\n        pbest = np.full(no_particle, np.inf)\n        pbestpos = np.zeros((no_particle, no_dim))\n        gbest = np.inf\n        gbestpos = np.zeros((no_dim,))\n\n        for i in range(iter):\n\n            for j, particle in enumerate(particles):\n\n                fitness = objective_function(particle, X_train, Y_train, X_test, Y_test)\n\n                if fitness < pbest[j]:\n                    pbest[j] = fitness\n                    pbestpos[j] = particle.copy()\n                if fitness < gbest:\n                    gbest = fitness\n                    gbestpos = particle.copy()\n\n            for j, particle in enumerate(particles):\n                iw = np.random.uniform(iw_range[0], iw_range[1], 1)[0]\n                velocities[j] = (\n                    iw * velocities[j]\n                    + (c[0] * np.random.uniform(0.0, 1.0, (no_dim,)) * (pbestpos[j] - particle))\n                    + (c[1] * np.random.uniform(0.0, 1.0, (no_dim,)) * (gbestpos - particle))\n                )\n                particles[j] += velocities[j]\n\n        return gbestpos\n\n    # Run PSO optimization\n    no_particle = 10\n    no_dim = 3\n    x_range = [(50, 200), (0.1, 0.5), (8, 32)]\n    v_range = [(1, 10), (0.01, 0.1), (1, 10)]\n    iw_range = (0.1, 0.5)\n    c = (1.4962, 1.4962)  # cognitive and social parameters\n    # Run PSO optimization\n    best_params = particle_swarm_optimization(objective_function, no_particle, no_dim, x_range, v_range, iw_range, c, x_train, y_train, x_test, y_test, 10, 2)\n\n    # Define the ranges for LSTM parameters\n    lstm_units, dropout_rate, dense_units = best_params\n\n    # Define the create the main lstm model for final prediction\n\n    def lstm_Model(lstm_units, dropout_rate, dense_units, n_past):\n        lstm_model = Sequential()\n        lstm_model.add(LSTM(units=int(lstm_units), return_sequences=True, input_shape=(n_past, 1)))\n        lstm_model.add(Dropout(dropout_rate))\n        lstm_model.add(LSTM(units=int(lstm_units/2), return_sequences=False))\n        lstm_model.add(Dropout(dropout_rate))\n        lstm_model.add(Dense(int(dense_units), activation='relu'))\n        lstm_model.add(Dense(1))\n        lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n\n        return lstm_model\n\n    # Train the LSTM model\n    lstm_model = lstm_Model(lstm_units, dropout_rate, dense_units, n_past)\n    history = lstm_model.fit(x_train_lstm, y_train, epochs=200, validation_data=(x_test_lstm, y_test), verbose=2)\n    \n    ######################################### END ###########################################\n    \n    folder_path = \"/kaggle/working/PSO/\"  # Get the current script's directory\n    filename_a = folder_path+filename+'_PSO.keras'\n    lstm_model.save(filename_a)\n\n#     model = tf.keras.models.load_model(filename_a)\n    \n    # Plotting the learning curve\n\n    predictions = lstm_model.predict(x_test)\n    # Inverse transform the predicted and actual prices\n    predicted_prices = scaler.inverse_transform(predictions)\n    actual_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n    # Calculate evaluation metrics\n    r2 = r2_score(actual_prices, predicted_prices)\n    mae = mean_absolute_error(actual_prices, predicted_prices)\n    mse = mean_squared_error(actual_prices, predicted_prices)\n    mape = np.mean(np.abs((actual_prices - predicted_prices) / actual_prices)) * 100\n\n    # Print evaluation metrics\n    print(\"R-squared:\", r2)\n    print(\"MAE:\", mae)\n    print(\"MSE:\", mse)\n    print(\"MAPE:\", mape)\n\n    # Plot actual vs predicted prices\n    plt.plot(actual_prices, label='Actual')\n    plt.plot(predicted_prices, label='Predicted')\n    plt.title(stockname+'-PSO')\n#     plt.title('Stock Price Prediction using LSTM+PSO')\n    plt.xlabel('Time')\n    plt.ylabel('Stock Price')\n    plt.legend()\n    plt_name = folder_path+filename+'_PSO.png'\n    plt.savefig(plt_name)\n    plt.show()","metadata":{"_uuid":"f11e5f11-8997-4ca9-864c-a1167c995839","_cell_guid":"f2574be9-d3f5-41b9-bf09-f102296a404a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-09T11:19:26.695743Z","iopub.execute_input":"2024-04-09T11:19:26.696182Z","iopub.status.idle":"2024-04-09T11:19:26.733418Z","shell.execute_reply.started":"2024-04-09T11:19:26.696152Z","shell.execute_reply":"2024-04-09T11:19:26.732503Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"stock_list = [\"AAPL\",\"AMGN\",\"AXP\",\"BA\",\"CAT\",\"CRM\",\"CSCO\",\"CVX\",\"DIS\",\"DOW\",\"GS\",\"HD\",\"HON\",\n              \"IBM\",\"INTC\",\"JNJ\",\"JPM\",\"KO\",\"MCD\",\"MMM\",\"MRK\",\"MSFT\",\"NKE\",\"PG\",\"TRV\",\"UNH\",\n              \"V\",\"VZ\",\"WBA\",\"WMT\"]\nprint(len(stock_list))","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:19:29.443633Z","iopub.execute_input":"2024-04-09T11:19:29.444282Z","iopub.status.idle":"2024-04-09T11:19:29.449928Z","shell.execute_reply.started":"2024-04-09T11:19:29.444252Z","shell.execute_reply":"2024-04-09T11:19:29.449004Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"30\n","output_type":"stream"}]},{"cell_type":"code","source":"for stock in stock_list:\n    stock_predict(stock,stock)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T11:19:39.630710Z","iopub.execute_input":"2024-04-09T11:19:39.631425Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"[*********************100%%**********************]  1 of 1 completed\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd /kaggle/working\n!zip -r PSO.zip /kaggle/working/PSO  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}